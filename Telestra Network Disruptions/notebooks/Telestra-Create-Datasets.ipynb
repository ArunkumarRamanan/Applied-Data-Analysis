{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_to_num(string):\n",
    "    return int(string.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load train and test files\n",
    "train = pd.read_csv('../data/train.csv', converters={'location': str_to_num})\n",
    "test = pd.read_csv('../data/test.csv', converters={'location': str_to_num})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate both train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train[['location']], test[['location']]], axis=0)\n",
    "data.index = np.arange(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load other files\n",
    "\n",
    "event_types = pd.read_csv('../data/event_type.csv', converters={'event_type': str_to_num})\n",
    "log_features = pd.read_csv('../data/log_feature.csv', converters={'log_feature': str_to_num})\n",
    "resource_types = pd.read_csv('../data/resource_type.csv', converters={'resource_type': str_to_num})\n",
    "severity_types = pd.read_csv('../data/severity_type.csv', converters={'severity_type': str_to_num})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Why did they choose index of severity types as the index of this new data frame ?\n",
    "# Because it has the severity types for all of the ids in train and test data frames\n",
    "\n",
    "X = pd.DataFrame(0, index=severity_types.index, columns= [])\n",
    "X['fault_severity'] = train.fault_severity # creates target variable in this new data frame\n",
    "X['severity_type'] = severity_types.severity_type # creates new feature for severity types\n",
    "X['location'] = data.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['num'] = X.groupby('location')['severity_type'].transform(lambda x: np.arange(x.shape[0]) + 1)\n",
    "\n",
    "# three different types of normalizing ( Why create these normalized values ?)\n",
    "\n",
    "# Why are these features considered as useful, as clearly just by using these features we are not able to \n",
    "# separate records based on the severity of their faults ?\n",
    "\n",
    "X['numsh'] = X.groupby('location')['num'].transform(lambda x: x/(x.shape[0]+1))\n",
    "X['numsh0'] = X.groupby('location')['num'].transform(lambda x: (x-1)/(x.shape[0]))\n",
    "X['numsh1'] = X.groupby('location')['num'].transform(lambda x: x/(x.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# location counts\n",
    "lc = pd.DataFrame(data['location'].value_counts()).rename(columns={'location':'loc_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.merge(X, lc, how='left', left_on='location',right_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nevents = pd.DataFrame(event_types['id'].value_counts()).rename(columns={'id':'nevents'})\n",
    "X = pd.merge(X, nevents, right_index=True, left_index=True, how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evtypes = event_types.event_type.value_counts()\n",
    "common_events = evtypes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ohevents = event_types.loc[event_types.event_type.isin(common_events)].groupby(['id','event_type'])['id'].count()\n",
    "ohevents = ohevents.unstack().fillna(0).add_prefix('event_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.merge(X, ohevents, right_index=True, left_index=True, how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# log features\n",
    "log_features['logvolume'] = np.log(log_features.volume + 1)\n",
    "X['volsumlog'] = np.log1p(log_features.groupby('id')['volume'].agg('sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logvol = log_features.groupby('id')['logvolume'].agg(['count','min','mean','max','std','sum']).fillna(0).add_prefix('logvolume_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.merge(X, logvol, how='left', right_index=True, left_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_features = log_features.log_feature.value_counts().index\n",
    "ohlog = log_features.loc[log_features.log_feature.isin(common_features)].groupby(['id','log_feature'])['logvolume'].mean()\n",
    "ohlog = ohlog.unstack().fillna(0).add_prefix('logfeatvol_')\n",
    "X = pd.merge(X, ohlog, how='left', left_index=True, right_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X['logfeatle_min'] = log_features.groupby('id').apply(lambda df:df['log_feature'].values[df['volume'].values.argmin()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmean = lambda x: x.rolling(window=9,min_periods=1,center=True).mean()\n",
    "X.groupby('location')['logvolume_sum'].transform(rmean)\n",
    "X['logvolume_sum_ma9'] = X.groupby('location')['logvolume_sum'].transform(rmean)\n",
    "X['logvolume_sum_ma9_diff'] = X['logvolume_sum'] - X['logvolume_sum_ma9']\n",
    "X['volsumlog_ma9'] = X.groupby('location')['volsumlog'].transform(rmean)\n",
    "X['volsumlog_ma9_diff'] = X['volsumlog'] - X['volsumlog_ma9']\n",
    "ma = X.groupby('location')['logfeatvol_203'].transform(rmean)\n",
    "X['logfeatvol_203_ma9_diff'] = X['logfeatvol_203'] - ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# resource data\n",
    "\n",
    "nresources = pd.DataFrame(resource_types['id'].value_counts()).rename(columns={'id':'nresources'})\n",
    "X = pd.merge(X, nresources, right_index=True, left_index=True, how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot common resources\n",
    "restypes = resource_types.resource_type.value_counts()\n",
    "common_resources = restypes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohres = resource_types.loc[resource_types.resource_type.isin(common_resources)].groupby(['id','resource_type'])['resource_type'].count()\n",
    "ohres = ohres.unstack().fillna(0.).add_prefix('restype_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.merge(X, ohres, how='left', left_index=True, right_index=True).fillna(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = X.columns[1:]\n",
    "\n",
    "train_df = X[:train.shape[0]]\n",
    "test_df = X[train.shape[0]:][features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('../processed/processed_train.csv', index=False)\n",
    "test_df.to_csv('../processed/processed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
