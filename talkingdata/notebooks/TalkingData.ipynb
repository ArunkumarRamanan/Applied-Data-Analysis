{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "                                                                                                                                                                                                                    \n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_DIR = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_ev = pd.read_csv(os.path.join(DATA_DIR, 'app_events.csv'), dtype={'device_id': np.str})\n",
    "app_ev = app_ev.groupby(\"event_id\")[\"app_id\"].apply(\n",
    "    lambda x: \" \".join(set(\"app_id:\" + str(s) for s in x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv(os.path.join(DATA_DIR, 'events.csv'), dtype={'device_id': np.str})\n",
    "events[\"app_id\"] = events[\"event_id\"].map(app_ev)\n",
    "\n",
    "events = events.dropna()\n",
    "\n",
    "del app_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events = events[[\"device_id\", \"app_id\"]]\n",
    "\n",
    "events = events.groupby(\"device_id\")[\"app_id\"].apply(\n",
    "    lambda x: \" \".join(set(str(\" \".join(str(s) for s in x)).split(\" \"))))\n",
    "events = events.reset_index(name=\"app_id\")\n",
    "\n",
    "events = pd.concat([pd.Series(row['device_id'], row['app_id'].split(' '))\n",
    "                    for _, row in events.iterrows()]).reset_index()\n",
    "events.columns = ['app_id', 'device_id']\n",
    "\n",
    "\n",
    "pbd = pd.read_csv(os.path.join(DATA_DIR, 'phone_brand_device_model.csv'),\n",
    "                  dtype={'device_id': np.str})\n",
    "pbd.drop_duplicates('device_id', keep='first', inplace=True)\n",
    "\n",
    "\n",
    "train = pd.read_csv(os.path.join(DATA_DIR, 'gender_age_train.csv'),\n",
    "                    dtype={'device_id': np.str})\n",
    "train.drop([\"age\", \"gender\"], axis=1, inplace=True)\n",
    "\n",
    "test = pd.read_csv(os.path.join(DATA_DIR, 'gender_age_test.csv'),\n",
    "                   dtype={'device_id': np.str})\n",
    "test[\"group\"] = np.nan\n",
    "\n",
    "\n",
    "split_len = len(train)\n",
    "\n",
    "# Group Labels\n",
    "Y = train[\"group\"]\n",
    "lable_group = LabelEncoder()\n",
    "Y = lable_group.fit_transform(Y)\n",
    "device_id = test[\"device_id\"]\n",
    "\n",
    "# Concat\n",
    "Df = pd.concat((train, test), axis=0, ignore_index=True)\n",
    "\n",
    "Df = pd.merge(Df, pbd, how=\"left\", on=\"device_id\")\n",
    "Df[\"phone_brand\"] = Df[\"phone_brand\"].apply(lambda x: \"phone_brand:\" + str(x))\n",
    "Df[\"device_model\"] = Df[\"device_model\"].apply(\n",
    "    lambda x: \"device_model:\" + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#  Concat Feature\n",
    "###################\n",
    "\n",
    "f1 = Df[[\"device_id\", \"phone_brand\"]]   # phone_brand\n",
    "f2 = Df[[\"device_id\", \"device_model\"]]  # device_model\n",
    "f3 = events[[\"device_id\", \"app_id\"]]    # app_id\n",
    "\n",
    "del Df\n",
    "\n",
    "f1.columns.values[1] = \"feature\"\n",
    "f2.columns.values[1] = \"feature\"\n",
    "f3.columns.values[1] = \"feature\"\n",
    "\n",
    "FLS = pd.concat((f1, f2, f3), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User-Item-Feature\n"
     ]
    }
   ],
   "source": [
    "print(\"# User-Item-Feature\")\n",
    "\n",
    "device_ids = FLS[\"device_id\"].unique()\n",
    "feature_cs = FLS[\"feature\"].unique()\n",
    "\n",
    "data = np.ones(len(FLS))\n",
    "dec = LabelEncoder().fit(FLS[\"device_id\"])\n",
    "row = dec.transform(FLS[\"device_id\"])\n",
    "col = LabelEncoder().fit_transform(FLS[\"feature\"])\n",
    "sparse_matrix = sparse.csr_matrix(\n",
    "    (data, (row, col)), shape=(len(device_ids), len(feature_cs)))\n",
    "\n",
    "sparse_matrix = sparse_matrix[:, sparse_matrix.getnnz(0) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Feature Selection\n",
      "# Num of Features:  4823\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "#      Data\n",
    "##################\n",
    "\n",
    "train_row = dec.transform(train[\"device_id\"])\n",
    "train_sp = sparse_matrix[train_row, :]\n",
    "\n",
    "test_row = dec.transform(test[\"device_id\"])\n",
    "test_sp = sparse_matrix[test_row, :]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_sp, Y, train_size=.90, random_state=10)\n",
    "\n",
    "##################\n",
    "#   Feature Sel\n",
    "##################\n",
    "print(\"# Feature Selection\")\n",
    "selector = SelectPercentile(f_classif, percentile=23)\n",
    "\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "X_train = selector.transform(X_train)\n",
    "X_val = selector.transform(X_val)\n",
    "\n",
    "train_sp = selector.transform(train_sp)\n",
    "test_sp = selector.transform(test_sp)\n",
    "\n",
    "print(\"# Num of Features: \", X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 25 rounds.\n",
      "[0]\ttrain-mlogloss:2.413323\teval-mlogloss:2.423159\n",
      "[1]\ttrain-mlogloss:2.379340\teval-mlogloss:2.395015\n",
      "[2]\ttrain-mlogloss:2.354908\teval-mlogloss:2.375592\n",
      "[3]\ttrain-mlogloss:2.335667\teval-mlogloss:2.360797\n",
      "[4]\ttrain-mlogloss:2.319801\teval-mlogloss:2.348936\n",
      "[5]\ttrain-mlogloss:2.306331\teval-mlogloss:2.339183\n",
      "[6]\ttrain-mlogloss:2.294741\teval-mlogloss:2.331023\n",
      "[7]\ttrain-mlogloss:2.284633\teval-mlogloss:2.324107\n",
      "[8]\ttrain-mlogloss:2.275750\teval-mlogloss:2.318206\n",
      "[9]\ttrain-mlogloss:2.267856\teval-mlogloss:2.313138\n",
      "[10]\ttrain-mlogloss:2.260778\teval-mlogloss:2.308756\n",
      "[11]\ttrain-mlogloss:2.254479\teval-mlogloss:2.304960\n",
      "[12]\ttrain-mlogloss:2.248751\teval-mlogloss:2.301650\n",
      "[13]\ttrain-mlogloss:2.243585\teval-mlogloss:2.298773\n",
      "[14]\ttrain-mlogloss:2.238862\teval-mlogloss:2.296248\n",
      "[15]\ttrain-mlogloss:2.234560\teval-mlogloss:2.294042\n",
      "[16]\ttrain-mlogloss:2.230633\teval-mlogloss:2.292102\n",
      "[17]\ttrain-mlogloss:2.227014\teval-mlogloss:2.290406\n",
      "[18]\ttrain-mlogloss:2.223686\teval-mlogloss:2.288912\n",
      "[19]\ttrain-mlogloss:2.220618\teval-mlogloss:2.287602\n",
      "[20]\ttrain-mlogloss:2.217776\teval-mlogloss:2.286452\n",
      "[21]\ttrain-mlogloss:2.215143\teval-mlogloss:2.285441\n",
      "[22]\ttrain-mlogloss:2.212682\teval-mlogloss:2.284558\n",
      "[23]\ttrain-mlogloss:2.210416\teval-mlogloss:2.283785\n",
      "[24]\ttrain-mlogloss:2.208281\teval-mlogloss:2.283108\n",
      "[25]\ttrain-mlogloss:2.206297\teval-mlogloss:2.282521\n",
      "[26]\ttrain-mlogloss:2.204433\teval-mlogloss:2.282013\n",
      "[27]\ttrain-mlogloss:2.202687\teval-mlogloss:2.281570\n",
      "[28]\ttrain-mlogloss:2.201059\teval-mlogloss:2.281188\n",
      "[29]\ttrain-mlogloss:2.199533\teval-mlogloss:2.280865\n",
      "[30]\ttrain-mlogloss:2.198083\teval-mlogloss:2.280594\n",
      "[31]\ttrain-mlogloss:2.196723\teval-mlogloss:2.280364\n",
      "[32]\ttrain-mlogloss:2.195441\teval-mlogloss:2.280174\n",
      "[33]\ttrain-mlogloss:2.194215\teval-mlogloss:2.280020\n",
      "[34]\ttrain-mlogloss:2.193079\teval-mlogloss:2.279896\n",
      "[35]\ttrain-mlogloss:2.191999\teval-mlogloss:2.279800\n",
      "[36]\ttrain-mlogloss:2.190955\teval-mlogloss:2.279731\n",
      "[37]\ttrain-mlogloss:2.189988\teval-mlogloss:2.279683\n",
      "[38]\ttrain-mlogloss:2.189074\teval-mlogloss:2.279655\n",
      "[39]\ttrain-mlogloss:2.188185\teval-mlogloss:2.279643\n"
     ]
    }
   ],
   "source": [
    "## Model\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dvalid = xgb.DMatrix(X_val, y_val)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"num_class\": 12,\n",
    "    \"booster\": \"gblinear\",\n",
    "    \"max_depth\": 6,\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"eta\": 0.07,\n",
    "    \"silent\": 1,\n",
    "    \"alpha\": 3,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"subsample\": 0.9\n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "gbm = xgb.train(params, dtrain, 40, evals=watchlist,\n",
    "                early_stopping_rounds=25, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train\n"
     ]
    }
   ],
   "source": [
    "print(\"# Train\")\n",
    "dtrain = xgb.DMatrix(train_sp, Y)\n",
    "gbm = xgb.train(params, dtrain, 40, verbose_eval=True)\n",
    "y_pre = gbm.predict(xgb.DMatrix(test_sp))\n",
    "\n",
    "# Write results\n",
    "result = pd.DataFrame(y_pre, columns=lable_group.classes_)\n",
    "result[\"device_id\"] = device_id\n",
    "result = result.set_index(\"device_id\")\n",
    "result.to_csv('../submissions/fine_tune_xgboost.gz', index=True,\n",
    "              index_label='device_id', compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
